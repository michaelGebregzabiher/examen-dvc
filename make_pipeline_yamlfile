# Stage 1: Split the data Note: use dvc repro to run each stage
dvc stage add -n split_data \
-d src/data/split_data.py -d data/raw_data/raw.csv \
-o data/processed_data/X_train.csv -o data/processed_data/X_test.csv -o data/processed_data/y_train.csv -o data/processed_data/y_test.csv \
python src/data/split_data.py
#then after run dvc repro to execute the stage

# Stage 2: Normalize the data
dvc stage add -n normalize_data \
-d src/data/normalize_data.py -d data/processed_data/X_train.csv -d data/processed_data/X_test.csv \
-o data/processed_data/X_train_scaled.csv -o data/processed_data/X_test_scaled.csv -o models/scaler.pkl \
python src/data/normalize_data.py

# Stage 3: Hyperparameter tuning with GridSearchCV
dvc stage add -n gridsearch \
  -d src/models/gridsearch.py -d data/processed_data/X_train_scaled.csv -d data/processed_data/y_train.csv \
  -o models/best_params.pkl \
  python src/models/gridsearch.py

# Stage 4: Train the model
dvc stage add -n train_model \
  -d src/models/train_model.py -d data/processed_data/X_train_scaled.csv -d data/processed_data/y_train.csv -d models/best_params.pkl \
  -o models/model.pkl \
  python src/models/train_model.py

# Stage 5: Evaluate the model
dvc stage add -n evaluate_model \
-d src/models/eval_model.py -d data/processed_data/X_test_scaled.csv -d data/processed_data/y_test.csv -d models/model.pkl \
-m metrics/scores.json -o data/predictions.csv \
python src/models/eval_model.py
